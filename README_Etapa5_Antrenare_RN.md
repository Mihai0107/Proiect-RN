# ğŸ“˜ README â€“ Etapa 5: Configurarea È™i Antrenarea Modelului RN

**Disciplina:** ReÈ›ele Neuronale  
**InstituÈ›ie:** POLITEHNICA BucureÈ™ti â€“ FIIR  
**Student:** Radu Mihaita-Gheorghe 
**Link Repository GitHub:** https://github.com/Mihai0107/Proiect-RN.git
**Data predÄƒrii:** 11.12.2025

---

## Scopul Etapei 5

AceastÄƒ etapÄƒ corespunde punctului **6. Configurarea È™i antrenarea modelului RN** din lista de 9 etape - slide 2 **RN Specificatii proiect.pdf**.

**Obiectiv principal:** Antrenarea efectivÄƒ a modelului RN definit Ã®n Etapa 4, evaluarea performanÈ›ei È™i integrarea Ã®n aplicaÈ›ia completÄƒ.

**Pornire obligatorie:** Arhitectura completÄƒ È™i funcÈ›ionalÄƒ din Etapa 4:
- State Machine definit È™i justificat
- Cele 3 module funcÈ›ionale (Data Logging, RN, UI)
- Minimum 40% date originale Ã®n dataset

---

## PREREQUISITE â€“ Verificare Etapa 4 (OBLIGATORIU)

**Ãnainte de a Ã®ncepe Etapa 5, verificaÈ›i cÄƒ aveÈ›i din Etapa 4:**

- [x] **State Machine** definit È™i documentat Ã®n `docs/state_machine.png`
- [x] **ContribuÈ›ie â‰¥40% date originale** Ã®n `data/raw/` (100% generate)
- [x] **Modul 1 (Data Logging)** funcÈ›ional - produce CSV-uri
- [x] **Modul 2 (RN)** cu arhitecturÄƒ definitÄƒ
- [x] **Modul 3 (UI/Web Service)** funcÈ›ional cu model dummy
- [x] **Tabelul "Nevoie â†’ SoluÈ›ie â†’ Modul"** complet Ã®n README Etapa 4

---

## PregÄƒtire Date pentru Antrenare 

### DacÄƒ aÈ›i adÄƒugat date noi Ã®n Etapa 4 (contribuÈ›ia de 40%):

*NotÄƒ: Deoarece Ã®ntregul dataset a fost generat unitar Ã®n Etapa 4 (5000 samples), nu este necesarÄƒ o combinare suplimentarÄƒ. Datele au fost preprocesate consistent folosind `src/preprocesare_finala.py`.*

**Verificare rapidÄƒ:**
Datele sunt deja Ã®mpÄƒrÈ›ite È™i salvate Ã®n formatele `.npy` Ã®n folderele `data/train`, `data/validation`, `data/test`.

---

##  CerinÈ›e Structurate pe 3 Niveluri

### Nivel 1 â€“ Obligatoriu pentru ToÈ›i (70% din punctaj)

CompletaÈ›i **TOATE** punctele urmÄƒtoare:

1. **Antrenare model** definit Ã®n Etapa 4 pe setul final de date (100% originale, 5000 observaÈ›ii).
2. **Minimum 10 epoci**, batch size 32.
3. **ÃmpÄƒrÈ›ire stratificatÄƒ** train/validation/test: 70% / 15% / 15%.
4. **Tabel justificare hiperparametri** (vezi secÈ›iunea de mai jos - OBLIGATORIU).
5. **Metrici calculate pe test set:**
   *NotÄƒ: Proiectul fiind de tip Regresie (predicÈ›ie timp continuu), raportÄƒm MAE È™i R2.*
   - **MAE (Mean Absolute Error):** 6.4563 minute
   - **MSE (Mean Squared Error):** 290.6815
   - **R2 Score:** 0.9741 (Excelent - explicÄƒ 97.4% din variaÈ›ie)
6. **Salvare model antrenat** Ã®n `models/trained_model.keras`.
7. **Integrare Ã®n UI din Etapa 4:**
   - UI Ã®ncarcÄƒ modelul ANTRENAT.
   - InferenÈ›Äƒ REALÄ‚ demonstratÄƒ.
   - Screenshot Ã®n `docs/screenshots/inference_real.png`.

#### Tabel Hiperparametri È™i JustificÄƒri (OBLIGATORIU - Nivel 1)

CompletaÈ›i tabelul cu hiperparametrii folosiÈ›i È™i **justificaÈ›i fiecare alegere**:

| **Hiperparametru** | **Valoare AleasÄƒ** | **Justificare** |
|--------------------|-------------------|-----------------|
| Learning rate | 0.001 | Valoare standard pentru Adam optimizer; asigurÄƒ o convergenÈ›Äƒ stabilÄƒ fÄƒrÄƒ a oscila excesiv Ã®n jurul minimului global. |
| Batch size | 32 | Compromis optim Ã®ntre viteza de execuÈ›ie È™i stabilitatea gradientului pentru un dataset de 5000 linii. |
| Number of epochs | 100 | S-a utilizat Early Stopping (patience=10), modelul oprindu-se automat cÃ¢nd `val_loss` nu a mai scÄƒzut, prevenind overfitting-ul. |
| Optimizer | Adam | Algoritm adaptiv eficient pentru date tabulare È™i regresie, converge mai rapid decÃ¢t SGD clasic. |
| Loss function | MSE (Mean Squared Error) | FuncÈ›ie standard pentru regresie care penalizeazÄƒ pÄƒtratic erorile mari (outlierii), forÈ›Ã¢nd modelul sÄƒ fie precis pe cazurile extreme. |
| Activation functions | ReLU (Hidden), Linear (Output) | ReLU rezolvÄƒ problema vanishing gradient; Output Linear este **obligatoriu** pentru regresie (ne permite sÄƒ prezicem orice valoare pozitivÄƒ, ex: 45.5 min). |

---

### Nivel 2 â€“ Recomandat (85-90% din punctaj)

IncludeÈ›i **TOATE** cerinÈ›ele Nivel 1 + urmÄƒtoarele:

1. **Early Stopping** - activat (patience=10 pe `val_loss`).
2. **Grafic loss È™i val_loss** salvat Ã®n `docs/loss_curve.png`. AratÄƒ convergenÈ›a clarÄƒ È™i lipsa overfitting-ului major.
3. **AnalizÄƒ erori context industrial** (vezi secÈ›iunea dedicatÄƒ mai jos - OBLIGATORIU Nivel 2).

---

### Nivel 3 â€“ Bonus (pÃ¢nÄƒ la 100%)

**Activitate realizatÄƒ:** Compararea a 2 arhitecturi diferite.

Am antrenat un al doilea model (**Model Bonus**) cu o arhitecturÄƒ mult mai complexÄƒ (mai mulÈ›i neuroni, mai multe straturi È™i Dropout) pentru a verifica dacÄƒ creÈ™terea capacitÄƒÈ›ii de Ã®nvÄƒÈ›are reduce eroarea.

**Tabel Comparativ:**

| CaracteristicÄƒ | **Model Standard (Nivel 1)** | **Model Bonus (Nivel 3)** |
| :--- | :--- | :--- |
| **ArhitecturÄƒ** | Dense(64) -> Dense(32) -> Out(1) | Dense(128) -> Dropout(0.2) -> Dense(64) -> Dense(32) -> Out(1) |
| **Complexitate** | RedusÄƒ (Rapid È™i Eficient) | RidicatÄƒ (Mai lent, risc de overfitting) |
| **MAE (Eroare Medie)** | **6.4563 min** | **6.6183 min** |
| **Concluzie** | **Mai performant** | Mai slab (Overfitting) |

**Justificare Alegere FinalÄƒ:**
Rezultatele experimentale aratÄƒ cÄƒ **Modelul Bonus a obÈ›inut o eroare mai mare** (+0.16 minute) faÈ›Äƒ de cel standard. Acest lucru indicÄƒ faptul cÄƒ arhitectura complexÄƒ a suferit de **Overfitting** (a Ã®nceput sÄƒ memoreze zgomotul din datele de antrenare), nefiind capabilÄƒ sÄƒ generalizeze la fel de bine pe datele de test.

Prin urmare, am decis sÄƒ pÄƒstrÄƒm **Modelul Standard** pentru producÈ›ie, deoarece este:
1. Mai precis (MAE mai mic).
2. Mai rapid la inferenÈ›Äƒ.
3. Mai puÈ›in predispus la erori pe date noi.

---

## Verificare ConsistenÈ›Äƒ cu State Machine (Etapa 4)

Antrenarea È™i inferenÈ›a respectÄƒ fluxul din State Machine-ul definit Ã®n Etapa 4.

**Implementare concretÄƒ pentru PredicÈ›ie Livrare:**

| **Stare din Etapa 4** | **Implementare Ã®n Etapa 5** |
|-----------------------|-----------------------------|
| `LOAD_RESOURCES` | ÃncÄƒrcare model `models/trained_model.keras` È™i scaler `models/preprocessor.pkl` |
| `PREPROCESS_INPUT` | Transformare date user (StandardScaler + OneHot) folosind pipeline-ul salvat |
| `RN_INFERENCE` | Forward pass `model.predict()` cu modelul ANTRENAT |
| `DISPLAY_RESULT` | AfiÈ™are timp estimat (ex: "45 minute") Ã®n consolÄƒ |

**Ãn `src/demo_live.py` (UI actualizat):**
Modelul dummy a fost Ã®nlocuit cu:
```python
model = tf.keras.models.load_model('models/trained_model.keras')
prediction = model.predict(X_input)  # predicÈ›ie REALÄ‚ bazatÄƒ pe distanÈ›Äƒ È™i trafic